{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXioLqNy1iDL",
        "outputId": "980c32bc-0302-4e52-a407-6733a20a2b30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: NLTK in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from NLTK) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from NLTK) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from NLTK) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from NLTK) (4.66.4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Error loading punket: Package 'punket' not found in index\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ],
      "source": [
        "%pip install NLTK\n",
        "import nltk\n",
        "import nltk\n",
        "#nltk.download()\n",
        "nltk.download('punket')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "from nltk.tokenize import PunktSentenceTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wc1R9oH33Ly7",
        "outputId": "61ee1636-4062-4b03-a397-cb1e0ffa1b4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDlV7u_WvjB8",
        "outputId": "219dee20-cbf4-4bae-9954-7ee09ce14cb7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7LW8tba3bfT",
        "outputId": "57ef5dab-a993-4f49-86ca-08a08e559db7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['All work and no play makes jack a dull boy, all work and no play games']\n",
            "['All', 'work', 'and', 'no', 'play', 'makes', 'jack', 'a', 'dull', 'boy', ',', 'all', 'work', 'and', 'no', 'play', 'games']\n"
          ]
        }
      ],
      "source": [
        "data = \"All work and no play makes jack a dull boy, all work and no play games\"\n",
        "sen=sent_tokenize(data)\n",
        "print(sen)\n",
        "words=word_tokenize(data)\n",
        "print(words)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "l-KGcP7Z7f-j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9def470-ee4f-45c2-cb1a-5eed05a54ac6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['All', 'work', 'play', 'makes', 'jack', 'dull', 'boy', ',', 'work', 'play', 'games']\n"
          ]
        }
      ],
      "source": [
        "# stop words\n",
        "stopWords = set(stopwords.words('english'))\n",
        "wordsFiltered = []\n",
        "for w in words:\n",
        "    if w not in stopWords:\n",
        "        wordsFiltered.append(w)\n",
        "\n",
        "print(wordsFiltered)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# word stem same meaning\n",
        "ps = PorterStemmer()\n",
        "for word in words:\n",
        "    print(word + \":\" + ps.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMVMr1yp9Grb",
        "outputId": "ab4b921f-de44-4fbd-89e8-d80110850a6b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All:all\n",
            "work:work\n",
            "and:and\n",
            "no:no\n",
            "play:play\n",
            "makes:make\n",
            "jack:jack\n",
            "a:a\n",
            "dull:dull\n",
            "boy:boy\n",
            ",:,\n",
            "all:all\n",
            "work:work\n",
            "and:and\n",
            "no:no\n",
            "play:play\n",
            "games:game\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tagging it labels noun , verb such as\n",
        "\n",
        "data = []\n",
        "\n",
        "for sent in sen:\n",
        "    data = data + nltk.pos_tag(words)\n",
        "print(data)\n",
        "for word in data:\n",
        "    if 'NN' in word[1]:\n",
        "        print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqC0cB7g9UX1",
        "outputId": "7cd3dadf-a2fd-450a-c7f0-b4d789a8bddf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('All', 'DT'), ('work', 'NN'), ('and', 'CC'), ('no', 'DT'), ('play', 'NN'), ('makes', 'VBZ'), ('jack', 'RP'), ('a', 'DT'), ('dull', 'JJ'), ('boy', 'NN'), (',', ','), ('all', 'DT'), ('work', 'NN'), ('and', 'CC'), ('no', 'DT'), ('play', 'NN'), ('games', 'NNS')]\n",
            "('work', 'NN')\n",
            "('play', 'NN')\n",
            "('boy', 'NN')\n",
            "('work', 'NN')\n",
            "('play', 'NN')\n",
            "('games', 'NNS')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data=pd.read_table(\"/content/drive/MyDrive/RNN 772024/AFINN.txt\")\n",
        "#print(data)\n",
        "wc=[]\n",
        "for x in wordsFiltered:\n",
        "    for index,row in data.iterrows():\n",
        "        #print(row[0],row[1])\n",
        "        if x == row[0]:\n",
        "            wc.append(row[1])\n",
        "print(sum(wc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRGKWRq4-3Di",
        "outputId": "0de20b7e-7fc1-43b7-88de-46a94e65f9bf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lemmatization using NLTK (sentence correction)\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer=WordNetLemmatizer()\n",
        "input_str=\"been had done critcal cities mice\"\n",
        "input_str=word_tokenize(input_str)\n",
        "cs1=\"\"\n",
        "for word in input_str:\n",
        "    cs=lemmatizer.lemmatize(word)\n",
        "    cs1=cs1+\" \"+cs\n",
        "print(cs1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0642dh_S9v-v",
        "outputId": "f583e502-45e9-496e-fea1-09f0ffc4a977"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " been had done critcal city mouse\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZfcGeNyABoK",
        "outputId": "01e2a7b9-e99a-423a-d3c2-4d116342cbbe"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-2]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a= sum(wc)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CT62NdY3DuH7",
        "outputId": "1805be4a-a479-4208-a7a2-e9e9ca622833"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-2"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if a < 0:\n",
        "    print(\"negative\")\n",
        "elif a > 0:\n",
        "    print(\"positive\")\n",
        "else:\n",
        "    print(\"neutral\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKOu5Ah3FWSE",
        "outputId": "d4c861cd-7213-4c97-ae44-7f0c2f66dc6d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "negative\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}