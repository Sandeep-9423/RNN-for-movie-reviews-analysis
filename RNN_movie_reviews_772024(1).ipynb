{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXioLqNy1iDL",
        "outputId": "4d2a741a-dfae-40c0-cf2c-cc2dee8c4f33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: NLTK in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from NLTK) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from NLTK) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from NLTK) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from NLTK) (4.66.4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Error loading punket: Package 'punket' not found in index\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ],
      "source": [
        "%pip install NLTK\n",
        "import nltk\n",
        "import nltk\n",
        "#nltk.download()\n",
        "nltk.download('punket')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "from nltk.tokenize import PunktSentenceTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wc1R9oH33Ly7",
        "outputId": "8abfe01c-be2b-4c7e-b084-f622d4dd072f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7LW8tba3bfT",
        "outputId": "03733bf0-de13-446e-a82e-0368903ba47f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['All work and no play makes jack a dull boy, all work and no play games']\n",
            "['All', 'work', 'and', 'no', 'play', 'makes', 'jack', 'a', 'dull', 'boy', ',', 'all', 'work', 'and', 'no', 'play', 'games']\n"
          ]
        }
      ],
      "source": [
        "data = \"All work and no play makes jack a dull boy, all work and no play games\"\n",
        "sen=sent_tokenize(data)\n",
        "print(sen)\n",
        "words=word_tokenize(data)\n",
        "print(words)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-KGcP7Z7f-j"
      },
      "outputs": [],
      "source": [
        "# stop words\n",
        "stopWords = set(stopwords.words('english'))\n",
        "wordsFiltered = []\n",
        "for w in words:\n",
        "    if w not in stopWords:\n",
        "        wordsFiltered.append(w)\n",
        "\n",
        "print(wordsFiltered)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# word stem same meaning\n",
        "ps = PorterStemmer()\n",
        "for word in words:\n",
        "    print(word + \":\" + ps.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMVMr1yp9Grb",
        "outputId": "0b1348ac-6820-4064-9f5f-b8661c14a3cf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All:all\n",
            "work:work\n",
            "and:and\n",
            "no:no\n",
            "play:play\n",
            "makes:make\n",
            "jack:jack\n",
            "a:a\n",
            "dull:dull\n",
            "boy:boy\n",
            ",:,\n",
            "all:all\n",
            "work:work\n",
            "and:and\n",
            "no:no\n",
            "play:play\n",
            "games:game\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tagging it labels noun , verb such as\n",
        "\n",
        "data = []\n",
        "\n",
        "for sent in sen:\n",
        "    data = data + nltk.pos_tag(words)\n",
        "print(data)\n",
        "for word in data:\n",
        "    if 'NN' in word[1]:\n",
        "        print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqC0cB7g9UX1",
        "outputId": "27e88461-8b50-46f9-cabc-985341a4db4a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('All', 'DT'), ('work', 'NN'), ('and', 'CC'), ('no', 'DT'), ('play', 'NN'), ('makes', 'VBZ'), ('jack', 'RP'), ('a', 'DT'), ('dull', 'JJ'), ('boy', 'NN'), (',', ','), ('all', 'DT'), ('work', 'NN'), ('and', 'CC'), ('no', 'DT'), ('play', 'NN'), ('games', 'NNS')]\n",
            "('work', 'NN')\n",
            "('play', 'NN')\n",
            "('boy', 'NN')\n",
            "('work', 'NN')\n",
            "('play', 'NN')\n",
            "('games', 'NNS')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data=pd.read_table(\"/content/drive/MyDrive/RNN 772024/AFINN.txt\")\n",
        "#print(data)\n",
        "wc=[]\n",
        "for x in wordsFiltered:\n",
        "    for index,row in data.iterrows():\n",
        "        #print(row[0],row[1])\n",
        "        if x == row[0]:\n",
        "            wc.append(row[1])\n",
        "print(sum(wc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRGKWRq4-3Di",
        "outputId": "cd051366-ff16-4b3d-9600-d477efffb6f5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lemmatization using NLTK (sentence correction)\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer=WordNetLemmatizer()\n",
        "input_str=\"been had done critcal cities mice\"\n",
        "input_str=word_tokenize(input_str)\n",
        "cs1=\"\"\n",
        "for word in input_str:\n",
        "    cs=lemmatizer.lemmatize(word)\n",
        "    cs1=cs1+\" \"+cs\n",
        "print(cs1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0642dh_S9v-v",
        "outputId": "9901a980-cc3a-4f91-e3cc-431fd89f8f27"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " been had done critcal city mouse\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZfcGeNyABoK",
        "outputId": "68302dd7-1109-4229-f354-f1da799cd861"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-2]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a= sum(wc)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CT62NdY3DuH7",
        "outputId": "251df680-1738-4c04-a63f-de7352d6519e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-2"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if a < 0:\n",
        "    print(\"negative\")\n",
        "elif a > 0:\n",
        "    print(\"positive\")\n",
        "else:\n",
        "    print(\"neutral\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKOu5Ah3FWSE",
        "outputId": "5c523ddc-bfca-42e3-cdd2-5d4ee590e5a4"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "negative\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}